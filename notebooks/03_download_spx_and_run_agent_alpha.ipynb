{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3cd665c",
   "metadata": {},
   "source": [
    "# Download SPX Data to `market_data` and Run agent-alpha\n",
    "\n",
    "This notebook does two things:\n",
    "\n",
    "1. Downloads real SPX universe + prices data using `agent_alpha.data.download_spx_data`.\n",
    "2. Runs factor evaluation where features/factor are computed on all downloaded prices, while RankIC/ICIR/Ex-ante IR are evaluated only on the universe mask.\n",
    "\n",
    "Optional: run the full `AgentAlphaWorkflow` if `OPENAI_API_KEY` is set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9777dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "CURRENT_DIR = Path.cwd().resolve()\n",
    "candidate_roots = [CURRENT_DIR, CURRENT_DIR.parent, CURRENT_DIR.parent.parent]\n",
    "REPO_ROOT = next((p for p in candidate_roots if (p / \"agent_alpha\").exists()), None)\n",
    "if REPO_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find project root containing 'agent_alpha'. Open this notebook from agent-alpha/notebooks.\"\n",
    "    )\n",
    "NOTEBOOK_DIR = REPO_ROOT / \"notebooks\"\n",
    "if not NOTEBOOK_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Expected notebooks directory at: {NOTEBOOK_DIR}\")\n",
    "\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "MARKET_DATA_DIR = NOTEBOOK_DIR / \"market_data\"\n",
    "MARKET_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)\n",
    "print(\"MARKET_DATA_DIR:\", MARKET_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c13cc20",
   "metadata": {},
   "source": [
    "If your environment is missing data-download deps, run this once:\n",
    "\n",
    "```python\n",
    "%pip install yfinance requests beautifulsoup4 lxml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa616979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from agent_alpha.data.download_spx_data import build_spx_data\n",
    "\n",
    "START_DATE = \"2015-01-01\"\n",
    "END_DATE = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n",
    "BATCH_SIZE = 100\n",
    "PAUSE_SECONDS = 0.2\n",
    "\n",
    "summary = build_spx_data(\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    output_dir=MARKET_DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pause_seconds=PAUSE_SECONDS,\n",
    "    auto_adjust=True,\n",
    ")\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89796b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for file_path in sorted(MARKET_DATA_DIR.glob(\"spx_*.csv\")):\n",
    "    size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"{file_path.name}: {size_mb:.2f} MB\")\n",
    "\n",
    "prices_csv_path = MARKET_DATA_DIR / \"spx_prices.csv\"\n",
    "universe_csv_path = MARKET_DATA_DIR / \"spx_universe_filtered.csv\"\n",
    "\n",
    "display(pd.read_csv(prices_csv_path, nrows=5))\n",
    "display(pd.read_csv(universe_csv_path, nrows=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae7fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_csv_path = MARKET_DATA_DIR / \"spx_prices.csv\"\n",
    "universe_csv_path = MARKET_DATA_DIR / \"spx_universe_filtered.csv\"\n",
    "\n",
    "prices_df = pd.read_csv(prices_csv_path, parse_dates=[\"date\"])\n",
    "universe_mask = pd.read_csv(universe_csv_path, parse_dates=[\"date\"])\n",
    "\n",
    "panel = (\n",
    "    prices_df.rename(\n",
    "        columns={\n",
    "            \"date\": \"datetime\",\n",
    "            \"ticker\": \"instrument\",\n",
    "            \"open\": \"$open\",\n",
    "            \"high\": \"$high\",\n",
    "            \"low\": \"$low\",\n",
    "            \"close\": \"$close\",\n",
    "            \"volume\": \"$volume\",\n",
    "        }\n",
    "    )\n",
    "    .set_index([\"datetime\", \"instrument\"])\n",
    "    .sort_index()[[\"$open\", \"$high\", \"$low\", \"$close\", \"$volume\"]]\n",
    ")\n",
    "\n",
    "dates = panel.index.get_level_values(\"datetime\")\n",
    "instruments = panel.index.get_level_values(\"instrument\")\n",
    "print(\n",
    "    {\n",
    "        \"panel_rows\": int(len(panel)),\n",
    "        \"panel_tickers\": int(instruments.nunique()),\n",
    "        \"panel_dates\": int(dates.nunique()),\n",
    "        \"start\": str(dates.min().date()),\n",
    "        \"end\": str(dates.max().date()),\n",
    "        \"universe_rows\": int(len(universe_mask)),\n",
    "        \"universe_tickers\": int(universe_mask[\"ticker\"].nunique()),\n",
    "        \"universe_snapshot_dates\": int(universe_mask[\"date\"].nunique()),\n",
    "    }\n",
    ")\n",
    "panel.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from agent_alpha.evaluator import FactorEvaluator\n",
    "\n",
    "example_ast = {\n",
    "    \"version\": \"1\",\n",
    "    \"root\": {\n",
    "        \"type\": \"call\",\n",
    "        \"op\": \"RANK\",\n",
    "        \"args\": [\n",
    "            {\n",
    "                \"type\": \"call\",\n",
    "                \"op\": \"DELTA\",\n",
    "                \"args\": [\n",
    "                    {\"type\": \"var\", \"name\": \"$close\"},\n",
    "                    {\"type\": \"const\", \"value\": 5},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "evaluator = FactorEvaluator(periods=[1, 5, 10], min_cross_section=5)\n",
    "factor = evaluator.calculate_factor(panel, example_ast)\n",
    "forward_returns = evaluator.calculate_forward_returns(panel, periods=[1, 5, 10])\n",
    "metrics_all = evaluator.calculate_ex_ante_ir(factor, forward_returns)\n",
    "metrics_universe = evaluator.calculate_ex_ante_ir(\n",
    "    factor,\n",
    "    forward_returns,\n",
    "    universe_mask=universe_mask,\n",
    ")\n",
    "\n",
    "print(\"Example AST rank_ic_ir (all rows):\", metrics_all[\"rank_ic_ir\"])\n",
    "print(\"Example AST rank_ic_ir (universe-filtered):\", metrics_universe[\"rank_ic_ir\"])\n",
    "print(\"Universe evaluation scope:\", json.dumps(metrics_universe.get(\"evaluation_scope\", {}), indent=2))\n",
    "display(factor.dropna().head(10))\n",
    "metrics_universe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c18be0",
   "metadata": {},
   "source": [
    "Optional full workflow with LLM (`gpt-5-mini`). This requires `OPENAI_API_KEY` in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e329c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from agent_alpha.workflow import AgentAlphaWorkflow\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"OPENAI_API_KEY is not set. Skipping LLM workflow run.\")\n",
    "else:\n",
    "    workflow = AgentAlphaWorkflow(model_name=\"gpt-5-mini\", periods=[1], max_attempts=2)\n",
    "    user_goal = (\n",
    "        \"Generate a robust SPX cross-sectional alpha from OHLCV data. \"\n",
    "        \"Keep the expression compact and interpretable.\"\n",
    "    )\n",
    "    state = workflow.run(\n",
    "        user_goal=user_goal,\n",
    "        panel=panel,\n",
    "        max_attempts=2,\n",
    "        universe_mask=universe_mask,\n",
    "    )\n",
    "\n",
    "    print(\"error:\", state.get(\"error\"))\n",
    "    print(\"hypothesis:\", state.get(\"hypothesis\"))\n",
    "    print(\"ast_expression:\", state.get(\"ast_expression\"))\n",
    "    print(\"metrics:\", state.get(\"metrics\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
