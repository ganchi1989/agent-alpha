{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3cd665c",
   "metadata": {},
   "source": [
    "# Download SPX Data to `market_data` and Run agent-alpha\n",
    "\n",
    "This notebook does two things:\n",
    "\n",
    "1. Downloads real SPX universe + prices data using `agent_alpha.data.download_spx_data`.\n",
    "2. Runs factor evaluation where features/factor are computed on all downloaded prices, while RankIC/ICIR/Ex-ante IR are evaluated only on the universe mask.\n",
    "\n",
    "Optional: run the full `AgentAlphaWorkflow` if `OPENAI_API_KEY` is set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9777dbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTEBOOK_DIR: D:\\python scripts\\qalpha\\agent-alpha\\notebooks\n",
      "REPO_ROOT: D:\\python scripts\\qalpha\\agent-alpha\n",
      "MARKET_DATA_DIR: D:\\python scripts\\qalpha\\agent-alpha\\notebooks\\market_data\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "CURRENT_DIR = Path.cwd().resolve()\n",
    "candidate_roots = [CURRENT_DIR, CURRENT_DIR.parent, CURRENT_DIR.parent.parent]\n",
    "REPO_ROOT = next((p for p in candidate_roots if (p / \"agent_alpha\").exists()), None)\n",
    "if REPO_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find project root containing 'agent_alpha'. Open this notebook from agent-alpha/notebooks.\"\n",
    "    )\n",
    "NOTEBOOK_DIR = REPO_ROOT / \"notebooks\"\n",
    "if not NOTEBOOK_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Expected notebooks directory at: {NOTEBOOK_DIR}\")\n",
    "\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "MARKET_DATA_DIR = NOTEBOOK_DIR / \"market_data\"\n",
    "MARKET_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)\n",
    "print(\"MARKET_DATA_DIR:\", MARKET_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c13cc20",
   "metadata": {},
   "source": [
    "If your environment is missing data-download deps, run this once:\n",
    "\n",
    "```python\n",
    "%pip install yfinance requests beautifulsoup4 lxml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa616979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BCR: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$ALXN: possibly delisted; no timezone found\n",
      "$AGN: possibly delisted; no timezone found\n",
      "$ALTR: possibly delisted; no timezone found\n",
      "$ARG: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$ARNC: possibly delisted; no timezone found\n",
      "$AVP: possibly delisted; no timezone found\n",
      "$BHI: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$ATVI: possibly delisted; no timezone found\n",
      "$ACE: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$ANSS: possibly delisted; no timezone found\n",
      "$ADS: possibly delisted; no timezone found\n",
      "$ABMD: possibly delisted; no timezone found\n",
      "\n",
      "13 Failed downloads:\n",
      "['BCR', 'ARG', 'BHI', 'ACE']: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "['ALXN', 'AGN', 'ALTR', 'ARNC', 'AVP', 'ATVI', 'ANSS', 'ADS', 'ABMD']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tickers=100 rows=228,270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BRCM: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$CERN: possibly delisted; no timezone found\n",
      "$CTXS: possibly delisted; no timezone found\n",
      "$CXO: possibly delisted; no timezone found\n",
      "$CSC: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$CELG: possibly delisted; no timezone found\n",
      "$BXLT: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$CPGX: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$DFS: possibly delisted; no timezone found\n",
      "$COV: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$CVC: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$CMCSK: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$CFN: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$CHK: possibly delisted; no timezone found\n",
      "$CTLT: possibly delisted; no timezone found\n",
      "\n",
      "15 Failed downloads:\n",
      "['BRCM', 'CSC', 'BXLT', 'CPGX', 'COV', 'CVC', 'CMCSK', 'CFN']: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "['CERN', 'CTXS', 'CXO', 'CELG', 'DFS', 'CHK', 'CTLT']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2: tickers=100 rows=215,177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GAS: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$DTV: possibly delisted; no timezone found\n",
      "$DISCK: possibly delisted; no timezone found\n",
      "$FRC: possibly delisted; no timezone found\n",
      "$DO: possibly delisted; no timezone found\n",
      "$GGP: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$DPS: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$ETFC: possibly delisted; no timezone found\n",
      "$FLIR: possibly delisted; no timezone found\n",
      "$DISCA: possibly delisted; no timezone found\n",
      "$DWDP: possibly delisted; no timezone found\n",
      "$ENDP: possibly delisted; no timezone found\n",
      "$FTR: possibly delisted; no timezone found\n",
      "$DISH: possibly delisted; no timezone found\n",
      "$ESV: possibly delisted; no timezone found\n",
      "$DRE: possibly delisted; no timezone found\n",
      "$FDO: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$FL: possibly delisted; no timezone found\n",
      "$DNR: possibly delisted; no timezone found\n",
      "$FBHS: possibly delisted; no timezone found\n",
      "$DNB: possibly delisted; no timezone found\n",
      "\n",
      "21 Failed downloads:\n",
      "['GAS', 'GGP', 'DPS', 'FDO']: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "['DTV', 'DISCK', 'FRC', 'DO', 'ETFC', 'FLIR', 'DISCA', 'DWDP', 'ENDP', 'FTR', 'DISH', 'ESV', 'DRE', 'FL', 'DNR', 'FBHS', 'DNB']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3: tickers=100 rows=205,675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HSP: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$HBI: possibly delisted; no timezone found\n",
      "$KRFT: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$K: possibly delisted; no timezone found\n",
      "$GPS: possibly delisted; no timezone found\n",
      "$JOY: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$HES: possibly delisted; no timezone found\n",
      "$JNPR: possibly delisted; no timezone found\n",
      "$HCBK: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$JWN: possibly delisted; no timezone found\n",
      "$HFC: possibly delisted; no timezone found\n",
      "$GMCR: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$IPG: possibly delisted; no timezone found\n",
      "$KSU: possibly delisted; no timezone found\n",
      "\n",
      "14 Failed downloads:\n",
      "['HSP', 'KRFT', 'JOY', 'HCBK', 'GMCR']: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "['HBI', 'K', 'GPS', 'HES', 'JNPR', 'JWN', 'HFC', 'IPG', 'KSU']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4: tickers=100 rows=229,125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MNK: possibly delisted; no timezone found\n",
      "$NLSN: possibly delisted; no timezone found\n",
      "$MRO: possibly delisted; no timezone found\n",
      "$MXIM: possibly delisted; no timezone found\n",
      "$LM: possibly delisted; no timezone found\n",
      "$LO: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$MON: possibly delisted; no timezone found\n",
      "$MJN: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$LVLT: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$LLTC: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$LLL: possibly delisted; no timezone found\n",
      "$NBL: possibly delisted; no timezone found\n",
      "\n",
      "12 Failed downloads:\n",
      "['MNK', 'NLSN', 'MRO', 'MXIM', 'LM', 'MON', 'LLL', 'NBL']: possibly delisted; no timezone found\n",
      "['LO', 'MJN', 'LVLT', 'LLTC']: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5: tickers=100 rows=237,695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PBCT: possibly delisted; no timezone found\n",
      "$SIAL: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$SIVB: possibly delisted; no timezone found\n",
      "$PCP: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$RAI: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$PXD: possibly delisted; no timezone found\n",
      "$QEP: possibly delisted; no timezone found\n",
      "$PLL: possibly delisted; no timezone found\n",
      "$PDCO: possibly delisted; no timezone found\n",
      "$PETM: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$RTN: possibly delisted; no timezone found\n",
      "$RHT: possibly delisted; no timezone found\n",
      "$SNI: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "\n",
      "13 Failed downloads:\n",
      "['PBCT', 'SIVB', 'PXD', 'QEP', 'PLL', 'PDCO', 'RTN', 'RHT']: possibly delisted; no timezone found\n",
      "['SIAL', 'PCP', 'RAI', 'PETM', 'SNI']: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6: tickers=100 rows=219,678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TWC: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$TYC: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$SWY: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$VAR: possibly delisted; no timezone found\n",
      "$TWTR: possibly delisted; no timezone found\n",
      "$TSS: possibly delisted; no timezone found\n",
      "$SWN: possibly delisted; no timezone found\n",
      "$VIAB: possibly delisted; no timezone found\n",
      "$TIF: possibly delisted; no timezone found\n",
      "$STJ: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$WCG: possibly delisted; no timezone found\n",
      "$WBA: possibly delisted; no timezone found\n",
      "\n",
      "12 Failed downloads:\n",
      "['TWC', 'TYC', 'SWY', 'STJ']: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "['VAR', 'TWTR', 'TSS', 'SWN', 'VIAB', 'TIF', 'WCG', 'WBA']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7: tickers=100 rows=227,603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$WYN: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$WFM: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "$YHOO: possibly delisted; no timezone found\n",
      "$XLNX: possibly delisted; no timezone found\n",
      "$XEC: possibly delisted; no timezone found\n",
      "$XL: possibly delisted; no timezone found\n",
      "$WIN: possibly delisted; no timezone found\n",
      "\n",
      "7 Failed downloads:\n",
      "['WYN', 'WFM']: possibly delisted; no price data found  (1d 2015-01-01 -> 2026-02-18)\n",
      "['YHOO', 'XLNX', 'XEC', 'XL', 'WIN']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8: tickers=30 rows=64,108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'universe_path': 'D:\\\\python scripts\\\\qalpha\\\\agent-alpha\\\\notebooks\\\\market_data\\\\spx_universe.csv',\n",
       " 'prices_path': 'D:\\\\python scripts\\\\qalpha\\\\agent-alpha\\\\notebooks\\\\market_data\\\\spx_prices.csv',\n",
       " 'filtered_universe_path': 'D:\\\\python scripts\\\\qalpha\\\\agent-alpha\\\\notebooks\\\\market_data\\\\spx_universe_filtered.csv',\n",
       " 'agent_panel_path': 'D:\\\\python scripts\\\\qalpha\\\\agent-alpha\\\\notebooks\\\\market_data\\\\spx_agent_panel.csv',\n",
       " 'universe_rows': 1468631,\n",
       " 'prices_rows': 1627331,\n",
       " 'panel_rows': 1297210,\n",
       " 'n_universe_tickers': 730,\n",
       " 'n_price_tickers': 623,\n",
       " 'n_panel_tickers': 606,\n",
       " 'n_panel_dates': 2797}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agent_alpha.data.download_spx_data import build_spx_data\n",
    "\n",
    "START_DATE = \"2015-01-01\"\n",
    "END_DATE = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n",
    "BATCH_SIZE = 100\n",
    "PAUSE_SECONDS = 0.2\n",
    "\n",
    "summary = build_spx_data(\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    output_dir=MARKET_DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pause_seconds=PAUSE_SECONDS,\n",
    "    auto_adjust=True,\n",
    ")\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c89796b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spx_agent_panel.csv: 122.27 MB\n",
      "spx_prices.csv: 152.94 MB\n",
      "spx_universe.csv: 25.42 MB\n",
      "spx_universe_filtered.csv: 22.67 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>37.621143</td>\n",
       "      <td>37.739909</td>\n",
       "      <td>36.881144</td>\n",
       "      <td>37.054726</td>\n",
       "      <td>1529200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AA</td>\n",
       "      <td>35.550392</td>\n",
       "      <td>35.796805</td>\n",
       "      <td>35.102374</td>\n",
       "      <td>35.572796</td>\n",
       "      <td>4340408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AAL</td>\n",
       "      <td>51.430493</td>\n",
       "      <td>51.733694</td>\n",
       "      <td>50.284015</td>\n",
       "      <td>51.079918</td>\n",
       "      <td>10748600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AAP</td>\n",
       "      <td>140.634759</td>\n",
       "      <td>142.077385</td>\n",
       "      <td>137.679545</td>\n",
       "      <td>138.632553</td>\n",
       "      <td>509800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>24.671155</td>\n",
       "      <td>24.682230</td>\n",
       "      <td>23.776357</td>\n",
       "      <td>24.214897</td>\n",
       "      <td>212818400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker        open        high         low       close  \\\n",
       "0  2015-01-02      A   37.621143   37.739909   36.881144   37.054726   \n",
       "1  2015-01-02     AA   35.550392   35.796805   35.102374   35.572796   \n",
       "2  2015-01-02    AAL   51.430493   51.733694   50.284015   51.079918   \n",
       "3  2015-01-02    AAP  140.634759  142.077385  137.679545  138.632553   \n",
       "4  2015-01-02   AAPL   24.671155   24.682230   23.776357   24.214897   \n",
       "\n",
       "        volume  \n",
       "0    1529200.0  \n",
       "1    4340408.0  \n",
       "2   10748600.0  \n",
       "3     509800.0  \n",
       "4  212818400.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>in_universe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ABT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker  in_universe\n",
       "0  2015-01-02      A            1\n",
       "1  2015-01-02     AA            1\n",
       "2  2015-01-02   AAPL            1\n",
       "3  2015-01-02   ABBV            1\n",
       "4  2015-01-02    ABT            1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for file_path in sorted(MARKET_DATA_DIR.glob(\"spx_*.csv\")):\n",
    "    size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"{file_path.name}: {size_mb:.2f} MB\")\n",
    "\n",
    "prices_csv_path = MARKET_DATA_DIR / \"spx_prices.csv\"\n",
    "universe_csv_path = MARKET_DATA_DIR / \"spx_universe_filtered.csv\"\n",
    "\n",
    "display(pd.read_csv(prices_csv_path, nrows=5))\n",
    "display(pd.read_csv(universe_csv_path, nrows=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ae7fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'panel_rows': 1627331, 'panel_tickers': 623, 'panel_dates': 2797, 'start': '2015-01-02', 'end': '2026-02-17', 'universe_rows': 1310954, 'universe_tickers': 623, 'universe_snapshot_dates': 2797}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>$open</th>\n",
       "      <th>$high</th>\n",
       "      <th>$low</th>\n",
       "      <th>$close</th>\n",
       "      <th>$volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th>instrument</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015-01-02</th>\n",
       "      <th>A</th>\n",
       "      <td>37.621143</td>\n",
       "      <td>37.739909</td>\n",
       "      <td>36.881144</td>\n",
       "      <td>37.054726</td>\n",
       "      <td>1529200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>35.550392</td>\n",
       "      <td>35.796805</td>\n",
       "      <td>35.102374</td>\n",
       "      <td>35.572796</td>\n",
       "      <td>4340408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <td>51.430493</td>\n",
       "      <td>51.733694</td>\n",
       "      <td>50.284015</td>\n",
       "      <td>51.079918</td>\n",
       "      <td>10748600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>140.634759</td>\n",
       "      <td>142.077385</td>\n",
       "      <td>137.679545</td>\n",
       "      <td>138.632553</td>\n",
       "      <td>509800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>24.671155</td>\n",
       "      <td>24.682230</td>\n",
       "      <td>23.776357</td>\n",
       "      <td>24.214897</td>\n",
       "      <td>212818400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            $open       $high        $low      $close  \\\n",
       "datetime   instrument                                                   \n",
       "2015-01-02 A            37.621143   37.739909   36.881144   37.054726   \n",
       "           AA           35.550392   35.796805   35.102374   35.572796   \n",
       "           AAL          51.430493   51.733694   50.284015   51.079918   \n",
       "           AAP         140.634759  142.077385  137.679545  138.632553   \n",
       "           AAPL         24.671155   24.682230   23.776357   24.214897   \n",
       "\n",
       "                           $volume  \n",
       "datetime   instrument               \n",
       "2015-01-02 A             1529200.0  \n",
       "           AA            4340408.0  \n",
       "           AAL          10748600.0  \n",
       "           AAP            509800.0  \n",
       "           AAPL        212818400.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_csv_path = MARKET_DATA_DIR / \"spx_prices.csv\"\n",
    "universe_csv_path = MARKET_DATA_DIR / \"spx_universe_filtered.csv\"\n",
    "\n",
    "prices_df = pd.read_csv(prices_csv_path, parse_dates=[\"date\"])\n",
    "universe_mask = pd.read_csv(universe_csv_path, parse_dates=[\"date\"])\n",
    "\n",
    "panel = (\n",
    "    prices_df.rename(\n",
    "        columns={\n",
    "            \"date\": \"datetime\",\n",
    "            \"ticker\": \"instrument\",\n",
    "            \"open\": \"$open\",\n",
    "            \"high\": \"$high\",\n",
    "            \"low\": \"$low\",\n",
    "            \"close\": \"$close\",\n",
    "            \"volume\": \"$volume\",\n",
    "        }\n",
    "    )\n",
    "    .set_index([\"datetime\", \"instrument\"])\n",
    "    .sort_index()[[\"$open\", \"$high\", \"$low\", \"$close\", \"$volume\"]]\n",
    ")\n",
    "\n",
    "dates = panel.index.get_level_values(\"datetime\")\n",
    "instruments = panel.index.get_level_values(\"instrument\")\n",
    "print(\n",
    "    {\n",
    "        \"panel_rows\": int(len(panel)),\n",
    "        \"panel_tickers\": int(instruments.nunique()),\n",
    "        \"panel_dates\": int(dates.nunique()),\n",
    "        \"start\": str(dates.min().date()),\n",
    "        \"end\": str(dates.max().date()),\n",
    "        \"universe_rows\": int(len(universe_mask)),\n",
    "        \"universe_tickers\": int(universe_mask[\"ticker\"].nunique()),\n",
    "        \"universe_snapshot_dates\": int(universe_mask[\"date\"].nunique()),\n",
    "    }\n",
    ")\n",
    "panel.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629d66db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example AST rank_ic_ir (all rows): 0.00017761636530499308\n",
      "Example AST rank_ic_ir (universe-filtered): 0.012379439305265695\n",
      "Universe evaluation scope: {\n",
      "  \"universe_filter_applied\": true,\n",
      "  \"rows_total\": 1627331,\n",
      "  \"rows_in_scope\": 1420309,\n",
      "  \"n_tickers_total\": 623,\n",
      "  \"n_tickers_in_scope\": 623\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime    instrument\n",
       "2015-01-09  A             0.566787\n",
       "            AA            0.722022\n",
       "            AAL           0.155235\n",
       "            AAP           0.871841\n",
       "            AAPL          0.741877\n",
       "            ABBV          0.521661\n",
       "            ABT           0.638989\n",
       "            ACGL          0.624549\n",
       "            ACN           0.781588\n",
       "            ADBE          0.380866\n",
       "Name: factor, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'rank_ic': 0.0005762436425004962,\n",
       " 'rank_ic_ir': 0.012379439305265695,\n",
       " 'period_metrics': {'ret_1': {'rank_ic': 0.0028186791176473967,\n",
       "   'rank_ic_std': 0.044993780892988874,\n",
       "   'rank_ic_ir': 0.0626459715477393,\n",
       "   'n_days': 2792},\n",
       "  'ret_5': {'rank_ic': -0.002056539793829896,\n",
       "   'rank_ic_std': 0.04440275896905576,\n",
       "   'rank_ic_ir': -0.04631558582346418,\n",
       "   'n_days': 2792},\n",
       "  'ret_10': {'rank_ic': 0.0009665916036839877,\n",
       "   'rank_ic_std': 0.04645303506312933,\n",
       "   'rank_ic_ir': 0.020807932191521973,\n",
       "   'n_days': 2788}},\n",
       " 'primary_metric': 'rank_ic',\n",
       " 'evaluation_scope': {'universe_filter_applied': True,\n",
       "  'rows_total': 1627331,\n",
       "  'rows_in_scope': 1420309,\n",
       "  'n_tickers_total': 623,\n",
       "  'n_tickers_in_scope': 623}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from agent_alpha.evaluator import FactorEvaluator\n",
    "\n",
    "example_ast = {\n",
    "    \"version\": \"1\",\n",
    "    \"root\": {\n",
    "        \"type\": \"call\",\n",
    "        \"op\": \"RANK\",\n",
    "        \"args\": [\n",
    "            {\n",
    "                \"type\": \"call\",\n",
    "                \"op\": \"DELTA\",\n",
    "                \"args\": [\n",
    "                    {\"type\": \"var\", \"name\": \"$close\"},\n",
    "                    {\"type\": \"const\", \"value\": 5},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "evaluator = FactorEvaluator(periods=[1, 5, 10], min_cross_section=5)\n",
    "factor = evaluator.calculate_factor(panel, example_ast)\n",
    "forward_returns = evaluator.calculate_forward_returns(panel, periods=[1, 5, 10])\n",
    "metrics_all = evaluator.calculate_ex_ante_ir(factor, forward_returns)\n",
    "metrics_universe = evaluator.calculate_ex_ante_ir(\n",
    "    factor,\n",
    "    forward_returns,\n",
    "    universe_mask=universe_mask,\n",
    ")\n",
    "\n",
    "print(\"Example AST rank_ic_ir (all rows):\", metrics_all[\"rank_ic_ir\"])\n",
    "print(\"Example AST rank_ic_ir (universe-filtered):\", metrics_universe[\"rank_ic_ir\"])\n",
    "print(\"Universe evaluation scope:\", json.dumps(metrics_universe.get(\"evaluation_scope\", {}), indent=2))\n",
    "display(factor.dropna().head(10))\n",
    "metrics_universe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f053e2-3b86-4f0a-b11c-7e8cabd1643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c18be0",
   "metadata": {},
   "source": [
    "Optional full workflow with LLM (`gpt-5-mini`). This requires `OPENAI_API_KEY` in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e329c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from agent_alpha.workflow import AgentAlphaWorkflow\n",
    " \n",
    "workflow = AgentAlphaWorkflow(model_name=\"gpt-5-mini\", periods=[1], max_attempts=2)\n",
    "user_goal = (\n",
    "   \"Generate a robust SPX cross-sectional alpha hypothesis\" ,\n",
    "    \"Keep the expression compact and interpretable.\"\n",
    ")\n",
    "state = workflow.run(\n",
    "    user_goal=user_goal,\n",
    "    panel=panel,\n",
    "    max_attempts=2,\n",
    "    universe_mask=universe_mask,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aec1a0c-c71a-46bf-8c30-48dae09c1323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: None\n",
      "hypothesis: Alpha ∝ rank( μ_{20}[log(C/O)] / σ_{20}[returns] ) — long top decile, short bottom decile across SPX.\n",
      "blueprint_json {'hypothesis': 'Alpha ∝ rank( μ_{20}[log(C/O)] / σ_{20}[returns] ). Approximated by (μ20_close - μ20_open) / μ20_open, scaled by 20-day realized volatility, cross-sectionally ranked. Long top decile, short bottom decile across SPX.', 'components': [{'id': 'close_ma_20', 'feature': 'sma', 'params': {'period': 20, 'value': 'close', 'shift': 0}}, {'id': 'open_ma_20', 'feature': 'sma', 'params': {'period': 20, 'value': 'open', 'shift': 0}}, {'id': 'rv_20', 'feature': 'rv', 'params': {'period': 20, 'shift': 0}}], 'combine': {'type': 'call', 'op': 'RANK', 'args': [{'type': 'call', 'op': 'DIVIDE', 'args': [{'type': 'call', 'op': 'DIVIDE', 'args': [{'type': 'call', 'op': 'SUBTRACT', 'args': [{'type': 'component', 'id': 'close_ma_20'}, {'type': 'component', 'id': 'open_ma_20'}]}, {'type': 'component', 'id': 'open_ma_20'}]}, {'type': 'component', 'id': 'rv_20'}]}]}}\n",
      "ast_expression: RANK(DIVIDE(DIVIDE(SUBTRACT($cmp_close_ma_20, $cmp_open_ma_20), $cmp_open_ma_20), $cmp_rv_20))\n",
      "metrics: {'rank_ic': 0.0029000598638296675, 'rank_ic_ir': 0.06508959125681019, 'period_metrics': {'ret_1': {'rank_ic': 0.0029000598638296675, 'rank_ic_std': 0.04455489438222952, 'rank_ic_ir': 0.06508959125681019, 'n_days': 2777}}, 'primary_metric': 'rank_ic', 'evaluation_scope': {'universe_filter_applied': True, 'rows_total': 1627331, 'rows_in_scope': 1420309, 'n_tickers_total': 623, 'n_tickers_in_scope': 623}}\n",
      "ast_summary: RANK(DIVIDE(DIVIDE(SUBTRACT($cmp_close_ma_20, $cmp_open_ma_20), $cmp_open_ma_20), $cmp_rv_20)) [nodes=8, depth=5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"error:\", state.get(\"error\"))\n",
    "print(\"hypothesis:\", state.get(\"hypothesis\"))\n",
    "print( \"blueprint_json\",state.get(\"blueprint_json\"))\n",
    "print(\"ast_expression:\", state.get(\"ast_expression\"))\n",
    "print(\"metrics:\", state.get(\"metrics\"))\n",
    "print(\"ast_summary:\", state.get(\"ast_summary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb388f-a770-42be-964f-a7b50e7c70cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a41abcf-3e0d-402f-b7a2-45e158f26745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grandalf in c:\\users\\ganch\\anaconda3\\envs\\quantaalpha\\lib\\site-packages (0.8)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\ganch\\anaconda3\\envs\\quantaalpha\\lib\\site-packages (from grandalf) (3.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
